{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/maciejkula/spotlight.git 'C:\\Users\\Ria\\AppData\\Local\\Temp\\pip-install-rthw7ad9\\spotlight_ab4019eed63a4a609a4546211fae77be'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spotlight\n",
      "  Cloning https://github.com/maciejkula/spotlight.git (to revision master) to c:\\users\\ria\\appdata\\local\\temp\\pip-install-rthw7ad9\\spotlight_ab4019eed63a4a609a4546211fae77be\n",
      "  Resolved https://github.com/maciejkula/spotlight.git to commit 75f4c8c55090771b52b88ef1a00f75bb39f9f2a9\n",
      "Requirement already satisfied: torch>=0.4.0 in c:\\users\\ria\\anaconda\\lib\\site-packages (from spotlight) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ria\\anaconda\\lib\\site-packages (from torch>=0.4.0->spotlight) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ria\\anaconda\\lib\\site-packages (from torch>=0.4.0->spotlight) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ria\\anaconda\\lib\\site-packages (from torch>=0.4.0->spotlight) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ria\\anaconda\\lib\\site-packages (from torch>=0.4.0->spotlight) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ria\\anaconda\\lib\\site-packages (from torch>=0.4.0->spotlight) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ria\\anaconda\\lib\\site-packages (from jinja2->torch>=0.4.0->spotlight) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ria\\anaconda\\lib\\site-packages (from sympy->torch>=0.4.0->spotlight) (1.2.1)\n",
      "Building wheels for collected packages: spotlight\n",
      "  Building wheel for spotlight (setup.py): started\n",
      "  Building wheel for spotlight (setup.py): finished with status 'done'\n",
      "  Created wheel for spotlight: filename=spotlight-0.1.6-py3-none-any.whl size=34200 sha256=81de18eeb5bcb99a90c903e6b9df97c15db09abacbd91be6960aede4e9ef7dbd\n",
      "  Stored in directory: C:\\Users\\Ria\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-01sf630n\\wheels\\b9\\f3\\fe\\92d82f9670bddfb144c00f90c895f4ef990d7812627e23d8f3\n",
      "Successfully built spotlight\n",
      "Installing collected packages: spotlight\n",
      "  Attempting uninstall: spotlight\n",
      "    Found existing installation: spotlight 3.3.0\n",
      "    Uninstalling spotlight-3.3.0:\n",
      "      Successfully uninstalled spotlight-3.3.0\n",
      "Successfully installed spotlight-0.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/maciejkula/spotlight.git@master#egg=spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "from spotlight.evaluation import *\n",
    "from spotlight.interactions import Interactions\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "from spotlight.factorization.representations import BilinearNet\n",
    "from spotlight.layers import BloomEmbedding\n",
    "import torch\n",
    "from torch.optim import sparse_adam\n",
    "from spotlight.evaluation import mrr_score\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset_aggr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = dataset.UserID.values\n",
    "item_ids = dataset.ItemID.values\n",
    "ratings = dataset.avg_rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = Interactions(user_ids = np.array(user_ids, dtype=np.int32),\n",
    "                            item_ids = np.array(item_ids, dtype=np.int32),\n",
    "                            ratings = np.array(ratings, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = user_based_train_test_split(interactions, test_percentage=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check train-test Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Interactions dataset (1043 users x 763 items x 767 interactions)>,\n",
       " <Interactions dataset (1043 users x 763 items x 163 interactions)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \"implicit factorization model\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImplicitFactorizationModel(loss='adaptive_hinge', \n",
    "                                   embedding_dim=128, \n",
    "                                   n_iter=100, \n",
    "                                   batch_size=32,\n",
    "                                   learning_rate=0.005,\n",
    "                                   l2=1e-6,\n",
    "                                   optimizer_func=sparse_adam.SparseAdam,\n",
    "                                   sparse=True,\n",
    "                                   num_negative_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.4447501270721356\n",
      "Epoch 1: loss 0.4262576376398404\n",
      "Epoch 2: loss 0.44228221227725345\n",
      "Epoch 3: loss 0.3707310526321332\n",
      "Epoch 4: loss 0.4426347290476163\n",
      "Epoch 5: loss 0.42974982783198357\n",
      "Epoch 6: loss 0.4396854527294636\n",
      "Epoch 7: loss 0.4607029954592387\n",
      "Epoch 8: loss 0.42780869950850803\n",
      "Epoch 9: loss 0.43639396503567696\n",
      "Epoch 10: loss 0.4694180463751157\n",
      "Epoch 11: loss 0.408333258703351\n",
      "Epoch 12: loss 0.3984564213703076\n",
      "Epoch 13: loss 0.45889636998375255\n",
      "Epoch 14: loss 0.4675477209190528\n",
      "Epoch 15: loss 0.43974290912350017\n",
      "Epoch 16: loss 0.3987838067114353\n",
      "Epoch 17: loss 0.4398944415152073\n",
      "Epoch 18: loss 0.44062893092632294\n",
      "Epoch 19: loss 0.4394723102450371\n",
      "Epoch 20: loss 0.4203199439992507\n",
      "Epoch 21: loss 0.4694607723504305\n",
      "Epoch 22: loss 0.41739627594749135\n",
      "Epoch 23: loss 0.4523144339521726\n",
      "Epoch 24: loss 0.3983288376281659\n",
      "Epoch 25: loss 0.4205563335369031\n",
      "Epoch 26: loss 0.4062804337590933\n",
      "Epoch 27: loss 0.4314301609992981\n",
      "Epoch 28: loss 0.45942317321896553\n",
      "Epoch 29: loss 0.45483656972646713\n",
      "Epoch 30: loss 0.4379022251814604\n",
      "Epoch 31: loss 0.42491484868029755\n",
      "Epoch 32: loss 0.4320108958830436\n",
      "Epoch 33: loss 0.41409241159756977\n",
      "Epoch 34: loss 0.4192493086059888\n",
      "Epoch 35: loss 0.4111696494122346\n",
      "Epoch 36: loss 0.46535965489844483\n",
      "Epoch 37: loss 0.392113267754515\n",
      "Epoch 38: loss 0.4424756399045388\n",
      "Epoch 39: loss 0.42908989017208415\n",
      "Epoch 40: loss 0.4536172275741895\n",
      "Epoch 41: loss 0.3967031954477231\n",
      "Epoch 42: loss 0.40126392741998035\n",
      "Epoch 43: loss 0.4362558498978615\n",
      "Epoch 44: loss 0.4352555585404237\n",
      "Epoch 45: loss 0.43571305212875205\n",
      "Epoch 46: loss 0.43180330594380695\n",
      "Epoch 47: loss 0.4273100147644679\n",
      "Epoch 48: loss 0.4083596045772235\n",
      "Epoch 49: loss 0.44407620777686435\n",
      "Epoch 50: loss 0.46378806481758755\n",
      "Epoch 51: loss 0.43440191075205803\n",
      "Epoch 52: loss 0.4196820240467787\n",
      "Epoch 53: loss 0.4134495786080758\n",
      "Epoch 54: loss 0.4245553178091844\n",
      "Epoch 55: loss 0.45042367403705913\n",
      "Epoch 56: loss 0.46354611466328305\n",
      "Epoch 57: loss 0.42789822692672413\n",
      "Epoch 58: loss 0.4141181545952956\n",
      "Epoch 59: loss 0.4435550595323245\n",
      "Epoch 60: loss 0.4409597764412562\n",
      "Epoch 61: loss 0.44745841436088085\n",
      "Epoch 62: loss 0.4484250781436761\n",
      "Epoch 63: loss 0.4511583757897218\n",
      "Epoch 64: loss 0.42926158756017685\n",
      "Epoch 65: loss 0.4215431498984496\n",
      "Epoch 66: loss 0.4511765080193679\n",
      "Epoch 67: loss 0.4392117882768313\n",
      "Epoch 68: loss 0.43456119671463966\n",
      "Epoch 69: loss 0.4316282334427039\n",
      "Epoch 70: loss 0.4111097988982995\n",
      "Epoch 71: loss 0.4001910115281741\n",
      "Epoch 72: loss 0.4556088335812092\n",
      "Epoch 73: loss 0.45822926238179207\n",
      "Epoch 74: loss 0.4403999137381713\n",
      "Epoch 75: loss 0.44025229662656784\n",
      "Epoch 76: loss 0.43468041345477104\n",
      "Epoch 77: loss 0.43391302476326626\n",
      "Epoch 78: loss 0.4734562324980895\n",
      "Epoch 79: loss 0.41997429355978966\n",
      "Epoch 80: loss 0.4301905495425065\n",
      "Epoch 81: loss 0.4298281576484442\n",
      "Epoch 82: loss 0.43564075355728465\n",
      "Epoch 83: loss 0.43999750539660454\n",
      "Epoch 84: loss 0.48141805827617645\n",
      "Epoch 85: loss 0.4449290794630845\n",
      "Epoch 86: loss 0.4228867714603742\n",
      "Epoch 87: loss 0.41095030804475147\n",
      "Epoch 88: loss 0.42800117780764896\n",
      "Epoch 89: loss 0.4510467356691758\n",
      "Epoch 90: loss 0.45655962886909646\n",
      "Epoch 91: loss 0.45431001484394073\n",
      "Epoch 92: loss 0.43426333367824554\n",
      "Epoch 93: loss 0.4449738065401713\n",
      "Epoch 94: loss 0.42949163913726807\n",
      "Epoch 95: loss 0.4373827042678992\n",
      "Epoch 96: loss 0.45087595904866856\n",
      "Epoch 97: loss 0.45592210193475086\n",
      "Epoch 98: loss 0.4314699061214924\n",
      "Epoch 99: loss 0.4289430833111207\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average MRR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mrr = mrr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg MRR score (for test data): 0.04516683011237628'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Avg MRR score (for test data): {avg_mrr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = rmse_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE score (for test data): 2.4094338417053223'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'RMSE score (for test data): {rmse}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall at k:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the train set,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [1.  1.  1.  0.5 1.  0.6 1.  1.  1.  0.5 1.  0.2 1.  0.5 0.5 0.1 1.  1.\n",
      " 1.  1.  1.  1.  1.  0.4 1.  1.  0.5 1.  1.  1.  0.5 0.5 1.  1.  0.5]\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=35, minmax=(0.1, 1.0), mean=0.8085714285714285, variance=0.0790420168067227, skewness=-0.9831397513594327, kurtosis=-0.46830606854289325)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall per user: [1.         0.33333333 0.83333333 1.         0.47619048 1.\n",
      " 0.4        0.14285714 1.         1.         0.14285714 1.\n",
      " 0.66666667 1.         1.         1.         0.66666667 0.07194245\n",
      " 0.4        1.         1.         0.25       1.         1.\n",
      " 0.5        1.         1.         1.         0.5        0.0862069\n",
      " 1.         1.         0.625      1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall per user: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=35, minmax=(0.07194244604316546, 1.0), mean=0.7455729744142758, variance=0.11152892291035478, skewness=-0.8223172797515813, kurtosis=-0.8743828602342836)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [0.8 0.  0.2 0.  0.1 0.3 0. ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=7, minmax=(0.0, 0.8), mean=0.2, variance=0.08333333333333337, skewness=1.436796436521193, kurtosis=0.7687999999999966)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall per user: [0.08080808 0.         0.4        0.         0.05       0.12\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall per user: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=7, minmax=(0.0, 0.4), mean=0.09297258297258297, variance=0.020487106271954755, skewness=1.6249972607888974, kurtosis=1.2223200671000667)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \"explicit factorization model\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExplicitFactorizationModel(loss='poisson', \n",
    "                                   embedding_dim=128, \n",
    "                                   n_iter=150, \n",
    "                                   batch_size=32,\n",
    "                                   learning_rate=0.005,\n",
    "                                   l2=1e-6,\n",
    "                                   optimizer_func=sparse_adam.SparseAdam,\n",
    "                                   sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.9886945361892382\n",
      "Epoch 1: loss 0.9572712853550911\n",
      "Epoch 2: loss 0.9152253742019335\n",
      "Epoch 3: loss 0.8521202057600021\n",
      "Epoch 4: loss 0.7540346110860506\n",
      "Epoch 5: loss 0.6198508950571219\n",
      "Epoch 6: loss 0.47021986668308574\n",
      "Epoch 7: loss 0.3294908568883936\n",
      "Epoch 8: loss 0.23237766899789372\n",
      "Epoch 9: loss 0.16765623477598032\n",
      "Epoch 10: loss 0.11715756054036319\n",
      "Epoch 11: loss 0.07552980119362473\n",
      "Epoch 12: loss 0.04367559403181076\n",
      "Epoch 13: loss 0.021272726046542328\n",
      "Epoch 14: loss 0.002850098283185313\n",
      "Epoch 15: loss -0.011957877781242132\n",
      "Epoch 16: loss -0.023910506318012874\n",
      "Epoch 17: loss -0.03260742500424385\n",
      "Epoch 18: loss -0.04073225846514106\n",
      "Epoch 19: loss -0.04711195221170783\n",
      "Epoch 20: loss -0.05247923064356049\n",
      "Epoch 21: loss -0.057306456845253706\n",
      "Epoch 22: loss -0.060858188662678\n",
      "Epoch 23: loss -0.06391689057151477\n",
      "Epoch 24: loss -0.06628733462033172\n",
      "Epoch 25: loss -0.06891396626209219\n",
      "Epoch 26: loss -0.07036111402946214\n",
      "Epoch 27: loss -0.07243925201085706\n",
      "Epoch 28: loss -0.07330916387339433\n",
      "Epoch 29: loss -0.07411700471614797\n",
      "Epoch 30: loss -0.07494032802060246\n",
      "Epoch 31: loss -0.07588338347462316\n",
      "Epoch 32: loss -0.07736739159251253\n",
      "Epoch 33: loss -0.07796472916379571\n",
      "Epoch 34: loss -0.07861810658747952\n",
      "Epoch 35: loss -0.07931736220295231\n",
      "Epoch 36: loss -0.07980466649557154\n",
      "Epoch 37: loss -0.08058252775420745\n",
      "Epoch 38: loss -0.0803761597101887\n",
      "Epoch 39: loss -0.08108027620861928\n",
      "Epoch 40: loss -0.08151529636234045\n",
      "Epoch 41: loss -0.08148700185120106\n",
      "Epoch 42: loss -0.08194107383800049\n",
      "Epoch 43: loss -0.08221025586438675\n",
      "Epoch 44: loss -0.08259227483843763\n",
      "Epoch 45: loss -0.0829018303193152\n",
      "Epoch 46: loss -0.08306221539775531\n",
      "Epoch 47: loss -0.08310821341971557\n",
      "Epoch 48: loss -0.08324804940881829\n",
      "Epoch 49: loss -0.08349201207359631\n",
      "Epoch 50: loss -0.08358609490096569\n",
      "Epoch 51: loss -0.08346282923594117\n",
      "Epoch 52: loss -0.08379043871536851\n",
      "Epoch 53: loss -0.08386538138923545\n",
      "Epoch 54: loss -0.08406278785939018\n",
      "Epoch 55: loss -0.08419719870047022\n",
      "Epoch 56: loss -0.08429030204812686\n",
      "Epoch 57: loss -0.08419344279294212\n",
      "Epoch 58: loss -0.08501021983101964\n",
      "Epoch 59: loss -0.08477372489869595\n",
      "Epoch 60: loss -0.08435109288742144\n",
      "Epoch 61: loss -0.08472740991661946\n",
      "Epoch 62: loss -0.08508194688086708\n",
      "Epoch 63: loss -0.08527426545818646\n",
      "Epoch 64: loss -0.08471118084465463\n",
      "Epoch 65: loss -0.08549184010674556\n",
      "Epoch 66: loss -0.08480986440554261\n",
      "Epoch 67: loss -0.08493557432666421\n",
      "Epoch 68: loss -0.08558367852432032\n",
      "Epoch 69: loss -0.08505359788735707\n",
      "Epoch 70: loss -0.08524466725066304\n",
      "Epoch 71: loss -0.08559984294697642\n",
      "Epoch 72: loss -0.08580696148176988\n",
      "Epoch 73: loss -0.08647688757628202\n",
      "Epoch 74: loss -0.08536612335592508\n",
      "Epoch 75: loss -0.08580286374005179\n",
      "Epoch 76: loss -0.08583802892826498\n",
      "Epoch 77: loss -0.0855013388209045\n",
      "Epoch 78: loss -0.0861641646673282\n",
      "Epoch 79: loss -0.08592122637977202\n",
      "Epoch 80: loss -0.08609368884935975\n",
      "Epoch 81: loss -0.08591623305498312\n",
      "Epoch 82: loss -0.0862331163759033\n",
      "Epoch 83: loss -0.0858227723898987\n",
      "Epoch 84: loss -0.0862698742809395\n",
      "Epoch 85: loss -0.08594655866424243\n",
      "Epoch 86: loss -0.08641415756816666\n",
      "Epoch 87: loss -0.08593614189885557\n",
      "Epoch 88: loss -0.08628959705432256\n",
      "Epoch 89: loss -0.08652012996996443\n",
      "Epoch 90: loss -0.08572292421013117\n",
      "Epoch 91: loss -0.0867895792859296\n",
      "Epoch 92: loss -0.08619368153934677\n",
      "Epoch 93: loss -0.08638766609753172\n",
      "Epoch 94: loss -0.08626066769162814\n",
      "Epoch 95: loss -0.08647447622691591\n",
      "Epoch 96: loss -0.08623987684647243\n",
      "Epoch 97: loss -0.08652219797174136\n",
      "Epoch 98: loss -0.08677858517815669\n",
      "Epoch 99: loss -0.0862934469866256\n",
      "Epoch 100: loss -0.08648250577971339\n",
      "Epoch 101: loss -0.08688602270558476\n",
      "Epoch 102: loss -0.08648135544111331\n",
      "Epoch 103: loss -0.08679398397604625\n",
      "Epoch 104: loss -0.08658039011061192\n",
      "Epoch 105: loss -0.08687246963381767\n",
      "Epoch 106: loss -0.08671433432027698\n",
      "Epoch 107: loss -0.0866232025437057\n",
      "Epoch 108: loss -0.0872929918890198\n",
      "Epoch 109: loss -0.08663530213137467\n",
      "Epoch 110: loss -0.08711310538152854\n",
      "Epoch 111: loss -0.08615237350265186\n",
      "Epoch 112: loss -0.08642867440357804\n",
      "Epoch 113: loss -0.08702624216675758\n",
      "Epoch 114: loss -0.08680709210845332\n",
      "Epoch 115: loss -0.08658406681691606\n",
      "Epoch 116: loss -0.08640694928665955\n",
      "Epoch 117: loss -0.08659228263422847\n",
      "Epoch 118: loss -0.08695829908053081\n",
      "Epoch 119: loss -0.0864706754994889\n",
      "Epoch 120: loss -0.08667143426525097\n",
      "Epoch 121: loss -0.08672313489175092\n",
      "Epoch 122: loss -0.08682330464944243\n",
      "Epoch 123: loss -0.08684989934166272\n",
      "Epoch 124: loss -0.08657578813532989\n",
      "Epoch 125: loss -0.08666470747751494\n",
      "Epoch 126: loss -0.08739484303320448\n",
      "Epoch 127: loss -0.08708524409060676\n",
      "Epoch 128: loss -0.0870169522240758\n",
      "Epoch 129: loss -0.08648657441760103\n",
      "Epoch 130: loss -0.0870475818713506\n",
      "Epoch 131: loss -0.08679017987257491\n",
      "Epoch 132: loss -0.08656343165785074\n",
      "Epoch 133: loss -0.08712984823311369\n",
      "Epoch 134: loss -0.0868258892345087\n",
      "Epoch 135: loss -0.08685377802855025\n",
      "Epoch 136: loss -0.08716326237966616\n",
      "Epoch 137: loss -0.08698010444641113\n",
      "Epoch 138: loss -0.08710181340575218\n",
      "Epoch 139: loss -0.08664454364528258\n",
      "Epoch 140: loss -0.08697148753950994\n",
      "Epoch 141: loss -0.08697565272450447\n",
      "Epoch 142: loss -0.08693316703041394\n",
      "Epoch 143: loss -0.08693965221755207\n",
      "Epoch 144: loss -0.08714158041402698\n",
      "Epoch 145: loss -0.0865297238342464\n",
      "Epoch 146: loss -0.08729542993629973\n",
      "Epoch 147: loss -0.08702029194682837\n",
      "Epoch 148: loss -0.08703749037037294\n",
      "Epoch 149: loss -0.0871485962998122\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average MRR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = mrr_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mrr = mrr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg MRR score (for test data): 0.05533418069794644'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Avg MRR score (for test data): {avg_mrr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = rmse_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE score (for test data): 1.5767426490783691'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'RMSE score (for test data): {rmse}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall at k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [0.7 0.  0.  0.1 0.2 0.2 0. ]\n",
      "DescribeResult(nobs=7, minmax=(0.0, 0.7), mean=0.17142857142857143, variance=0.06238095238095238, skewness=1.5279989960437383, kurtosis=1.0312044752636762)\n",
      "Recall per user: [0.07070707 0.         0.         1.         0.1        0.08\n",
      " 0.        ]\n",
      "DescribeResult(nobs=7, minmax=(0.0, 1.0), mean=0.1786724386724387, variance=0.13298876790998002, skewness=1.9830330394777387, kurtosis=2.0395790085717636)\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')\n",
    "print(describe(precision))\n",
    "print(f'Recall per user: {recall}')\n",
    "print(describe(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Bloom Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_ratio = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings = BloomEmbedding(interactions.num_users, 32,\n",
    "                                 compression_ratio=compression_ratio,\n",
    "                                 num_hash_functions=2)\n",
    "\n",
    "item_embeddings = BloomEmbedding(interactions.num_items, 32,\n",
    "                                 compression_ratio=compression_ratio,\n",
    "                                 num_hash_functions=2)\n",
    "\n",
    "network = BilinearNet(interactions.num_users,\n",
    "                      interactions.num_items,\n",
    "                      user_embedding_layer=user_embeddings,\n",
    "                      item_embedding_layer=item_embeddings)\n",
    "\n",
    "model = ExplicitFactorizationModel(loss='poisson',\n",
    "                                   n_iter=150,\n",
    "                                   batch_size=32,\n",
    "                                   learning_rate=1e-2,\n",
    "                                   l2=1e-6,\n",
    "                                   representation=network,\n",
    "                                   sparse=True,\n",
    "                                   use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg MRR score: 0.1662496893217771'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr = mrr_score(model, test, train=train)\n",
    "f'Avg MRR score: {np.mean(mrr)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE score (for test data): 1.410247802734375'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = rmse_score(model, test)\n",
    "f'RMSE score (for test data): {rmse}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, test, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [0.8 0.  0.1 0.1 0.1 0.1 0. ]\n",
      "DescribeResult(nobs=7, minmax=(0.0, 0.8), mean=0.17142857142857146, variance=0.07904761904761905, skewness=1.9182296278921176, kurtosis=1.9147554071708504)\n",
      "Recall per user: [0.08080808 0.         0.2        1.         0.05       0.04\n",
      " 0.        ]\n",
      "DescribeResult(nobs=7, minmax=(0.0, 1.0), mean=0.19582972582972585, variance=0.13036416254901104, skewness=1.8993750770276816, kurtosis=1.8324578093532988)\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')\n",
    "print(describe(precision))\n",
    "print(f'Recall per user: {recall}')\n",
    "print(describe(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unaggregated set, explicit model (with ratings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = dataset.UserID.values\n",
    "item_ids = dataset.ItemID.values\n",
    "\n",
    "ratings = dataset.Rating.values\n",
    "\n",
    "interactions = Interactions(user_ids = np.array(user_ids, dtype=np.int32),\n",
    "                            item_ids = np.array(item_ids, dtype=np.int32),\n",
    "                            ratings = np.array(ratings, dtype=np.float32))\n",
    "\n",
    "train, test = user_based_train_test_split(interactions, test_percentage=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Interactions dataset (1043 users x 763 items x 2764 interactions)>,\n",
       " <Interactions dataset (1043 users x 763 items x 1248 interactions)>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExplicitFactorizationModel(loss='poisson', \n",
    "                                   embedding_dim=256, \n",
    "                                   n_iter=200, \n",
    "                                   batch_size=32,\n",
    "                                   learning_rate=0.005,\n",
    "                                   l2=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avg MRR score: 0.028765395806446412'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr = mrr_score(model, test, train=train)\n",
    "f'Avg MRR score: {np.mean(mrr)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE score (for test data): 2.0668251514434814'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = rmse_score(model, test)\n",
    "f'RMSE score (for test data): {rmse}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = precision_recall_score(model, test, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per user: [0.  0.1 0.  0.1 0.  0.  0.  0.5 0.2 0.8 0.3 0.1 0.3]\n",
      "DescribeResult(nobs=13, minmax=(0.0, 0.8), mean=0.1846153846153846, variance=0.058076923076923075, skewness=1.4514612235559854, kurtosis=1.2723637852140994)\n",
      "Recall per user: [0.         0.03333333 0.         0.16666667 0.         0.\n",
      " 0.         0.125      0.1        0.06896552 0.12       0.2\n",
      " 0.1875    ]\n",
      "DescribeResult(nobs=13, minmax=(0.0, 0.2), mean=0.07703580901856764, variance=0.0059731395943643266, skewness=0.3305205617997852, kurtosis=-1.4039245990705647)\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision per user: {precision}')\n",
    "print(describe(precision))\n",
    "print(f'Recall per user: {recall}')\n",
    "print(describe(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite no user and item features used by the algorithms, we managed to get 1.5 RMSE and 20% precision at k-10. For RMSE, the performance is below algorithms like ALS or SVD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
